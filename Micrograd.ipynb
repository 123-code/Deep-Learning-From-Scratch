{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa+oj34x/jKDtnt+C/FQ+6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123-code/Deep-Learning-From-Scratch/blob/main/Micrograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBC30j9AJgKZ",
        "outputId": "ae90457e-f9e8-469e-ddfe-5b0fbc566434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: micrograd in /usr/local/lib/python3.9/dist-packages (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install micrograd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from micrograd.engine import Value\n",
        "import math\n",
        "\n",
        "class Value:\n",
        "  def __init__(self,data,_children=(),_op=\"\",label=\"\"):\n",
        "    self.data = data\n",
        "    self.grad = 0\n",
        "    self._backward = lambda: None\n",
        "    self.prev = set(_children)\n",
        "    self._op = _op\n",
        "    self.label = label\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return f\"Value(data={self.data})\"\n",
        "\n",
        "  def __add__(self,other):\n",
        "    result = Value(self.data + other.data,(self,other),\"+\")\n",
        "\n",
        "    def _backward():\n",
        "      self.grad = 1.0 * result.grad\n",
        "      other.grad = 1.0 * result.grad\n",
        "    result._backward = _backward\n",
        "\n",
        "    return result\n",
        "\n",
        "  def __mul__(self,other):\n",
        "    result = Value(self.data * other.data,(self,other),\"*\")\n",
        "\n",
        "    def _backward():\n",
        "      self.grad = other.data * result.grad\n",
        "      other.grad = self.data * result.grad\n",
        "\n",
        "    result._backward = _backward\n",
        "\n",
        "      \n",
        "      \n",
        "    return result\n",
        "\n",
        "  def tanh(self):\n",
        "    x = self.data\n",
        "    t = (math.exp(2*x)-1)/(math.exp(2*x)+12)\n",
        "    out = Value(t,(self,),'tanh')\n",
        "\n",
        "    def _backward():\n",
        "      self.grad = (1- t**2) * out.grad\n",
        "    out._backward = _backward\n",
        "    return out\n",
        "\n",
        "a = Value(2.0,label=\"a\")\n",
        "b =  Value(-3.0,label=\"b\")\n",
        "c = Value(10.0,label=\"c\")\n",
        "e = a*b; e.label=\"e\"\n",
        "#a + b\n",
        "d = e + c; d.label=\"d\"\n",
        "f = Value(-2.0,label=\"f\")\n",
        "l = d+f\n",
        "l\n",
        "# variable grad should store the gradient of the loss with respect to each value. \n",
        "\n"
      ],
      "metadata": {
        "id": "U9_IMQ-KSZDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e8e2db-4ff3-454f-cb3f-65bd3a6ec212"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(data=2.0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yn7FjHDFmO4U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = d*f\n",
        "f.grad = 4.0\n",
        "d.grad = -2\n"
      ],
      "metadata": {
        "id": "duciUfoq4R4p"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.grad = 1"
      ],
      "metadata": {
        "id": "H9kOpraP4BBb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dl/dc\n",
        "c.grad = -2.0\n",
        "e.grad = -2.0"
      ],
      "metadata": {
        "id": "vPoweVvX59nt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.data += 0.01 * a.grad\n",
        "b.data += 0.01 * b.grad\n",
        "c.data += 0.01 * c.grad\n",
        "f.data += 0.01 * f.grad\n",
        "\n",
        "e = a*b\n",
        "d = e+c\n",
        "l = d*f\n",
        "print(l.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5QrgR-mf0Uv",
        "outputId": "20b76924-13cf-4525-f437-2680ea08524e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7.800800000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of gradient check: Derivative of the loss against all the previous multiplication results."
      ],
      "metadata": {
        "id": "bUD4LSY25s0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lol():\n",
        "  h=0.001\n",
        "  a = Value(2.0,label=\"a\")\n",
        "  b =  Value(-3.0,label=\"b\")\n",
        "  c = Value(10.0,label=\"c\")\n",
        "  e = a*b; e.label=\"e\"\n",
        "#a + b\n",
        "  d = e + c; d.label=\"d\"\n",
        "  f = Value(-2.0,label=\"f\")\n",
        "  l = d*f\n",
        "  l1 = l.data\n",
        "\n",
        "\n",
        "  \n",
        "  a = Value(2.0 ,label=\"a\")\n",
        "  b =  Value(-3.0,label=\"b\")\n",
        "  c = Value(10.0,label=\"c\")\n",
        "  e = a*b; e.label=\"e\"\n",
        "  e.data += h\n",
        "#a + b\n",
        "  d = e + c; d.label=\"d\"\n",
        "  f = Value(-2.0 ,label=\"f\")\n",
        "  l = d*f\n",
        "  l2 = l.data\n",
        "  print((l2-l1)/h)\n",
        "\n",
        "lol()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WBrXBuQ3CZS",
        "outputId": "f8882fda-1c89-4d26-ca76-51f9f6994370"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.000000000000668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neuron basic code"
      ],
      "metadata": {
        "id": "NHLLKYAmh5Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "gOBmAQMLiyyZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs x1,x2\n",
        "x1 = Value(2.0,label='x1')\n",
        "x2=Value(0.0,label='x2')\n",
        "#weights w1,w2\n",
        "w1=Value(-3.0,label='w1')\n",
        "w2=Value(1.0,label='w2')\n",
        "\n",
        "# neuron bias\n",
        "b = Value(6.7,label='b')\n",
        "\n",
        "x1w1 = np.dot(x1,w1)\n",
        "x2w2 = np.dot(x2,w2)\n",
        "wsum = x1w1 * x2w2 + b\n",
        "o = wsum.tanh()\n",
        "print(o)\n",
        "print(wsum)\n",
        "\n",
        "#apply activation function\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvjGCx7ch_GV",
        "outputId": "479ffff0-b3c4-4b8f-ce72-d1548871c287"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value(data=0.9999803034846588)\n",
            "Value(data=6.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o.grad = 1.0"
      ],
      "metadata": {
        "id": "pcuu0xfzoVkk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o._backward()"
      ],
      "metadata": {
        "id": "J9BftrS0oIXy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wsum._backward()"
      ],
      "metadata": {
        "id": "17rw80z7o6iQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o.grad = 1.0\n",
        "1-o.data**2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJHZWxCDitHO",
        "outputId": "d3baf04a-e8c5-4dec-8474-ec4005de8e72"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.939264272967424e-05"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}